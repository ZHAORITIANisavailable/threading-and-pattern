import threading
import time
import torch
import psutil
import numpy as np
import torch.nn as nn
from collections import defaultdict, Counter
import matplotlib.pyplot as plt
import pandas as pd
from queue import Queue
import seaborn as sns
from IPython.display import display
import torch.nn.functional as F

from training import trainEE_KL, trainEE_KL_for_profiling



# === å¤šçº¿ç¨‹è®­ç»ƒæ§åˆ¶å™¨å°è£… ===
class TrainingController:
    def __init__(self):
        self.stop_event = threading.Event()
        self.request_queue = Queue()
        self.train_thread = None

    def start_training(self, train_function, **kwargs):
        """å¯åŠ¨è®­ç»ƒçº¿ç¨‹"""
        def _wrapper():
            train_function(
                stop_event=self.stop_event,
                request_queue=self.request_queue,
                **kwargs
            )
        self.stop_event.clear()
        self.train_thread = threading.Thread(target=_wrapper)
        self.train_thread.start()

    def add_request(self, data):
        """æ·»åŠ å®æ—¶æ¨ç†è¯·æ±‚ï¼ˆæš‚ä¸ç”¨äº A æ¨¡å¼ï¼‰"""
        self.request_queue.put(data)

    def stop_training(self):
        """åœæ­¢è®­ç»ƒçº¿ç¨‹"""
        self.stop_event.set()
        if self.train_thread:
            self.train_thread.join()

class Timer:
    def __init__(self, name="Timer"):
        self.name = name
        self.start_time = None

    def start(self):
        self.start_time = time.time()

    def stop(self):
        if self.start_time is None:
            print(f"{self.name} æœªå¼€å§‹è®¡æ—¶ï¼")
            return
        self.duration = time.time() - self.start_time
        print(f"[{self.name}] è€—æ—¶: {self.duration:.2f} ç§’\n")
        return self.duration
    def elapsed(self):
        return round(self.duration, 2)
    
def _visualize_exit_distribution(log_dict, title_suffix=""):
    if not log_dict or all(len(v) == 0 for v in log_dict.values()):
        print(f"[è·³è¿‡] {title_suffix} æ¨ç†æ•°æ®ä¸ºç©ºï¼Œæ— æ³•å¯è§†åŒ–ã€‚")
        return

    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
                   'dog', 'frog', 'horse', 'ship', 'truck']
    exit_class_dist = pd.DataFrame.from_dict(
        {k: Counter(v) for k, v in log_dict.items()},
        orient='index'
    ).fillna(0).astype(int)

    for i in range(len(class_names)):
        if i not in exit_class_dist.columns:
            exit_class_dist[i] = 0
    exit_class_dist = exit_class_dist[sorted(exit_class_dist.columns)]
    exit_class_dist.columns = class_names

    exit_class_dist.T.plot(kind='bar', figsize=(10, 5))
    plt.title(f"Exit-wise Class Distribution {title_suffix}")
    plt.xlabel("Class")
    plt.ylabel("Sample Count")
    plt.tight_layout()
    plt.show()

    plt.figure(figsize=(8, 4))
    sns.heatmap(exit_class_dist, annot=True, fmt='d', cmap='YlGnBu')
    plt.title(f"Exit-Class Heatmap {title_suffix}")
    plt.ylabel("Exit")
    plt.xlabel("Class")
    plt.tight_layout()
    plt.show()

    
def analyze_exit_logs_with_accuracy(all_logs, class_names):
    import pandas as pd
    import matplotlib.pyplot as plt
    import seaborn as sns

    df = pd.DataFrame(all_logs)

    # ===== 1. æ¯ä¸ªå‡ºå£çš„æ€»ä½“å‡†ç¡®ç‡ =====
    acc_stats = df.groupby('exit').apply(
        lambda g: pd.Series({
            'correct': (g['true'] == g['pred']).sum(),
            'total': len(g),
            'accuracy': (g['true'] == g['pred']).mean()
        })
    )

    print("\nğŸ“Š æ¯ä¸ªå‡ºå£çš„æ€»ä½“å‡†ç¡®ç‡ï¼š")
    print(acc_stats[['correct', 'total', 'accuracy']])

    # ===== 2. æ¯ä¸ªå‡ºå£ã€æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡ =====
    print("\nğŸ“š æ¯ä¸ªå‡ºå£çš„æ¯ç±»å‡†ç¡®ç‡ï¼ˆæŒ‰ true æ ‡ç­¾ç»Ÿè®¡ï¼‰ï¼š")
    grouped = df.groupby(['exit', 'true'])

    per_class_acc = {}
    for (exit_num, cls_id), group in grouped:
        correct = (group['pred'] == group['true']).sum()
        total = len(group)
        acc = correct / total if total > 0 else 0.0
        per_class_acc.setdefault(exit_num, {})[class_names[cls_id]] = acc

    # æ‰“å°æ¯ä¸ªå‡ºå£çš„ per-class å‡†ç¡®ç‡
    for exit_num in sorted(per_class_acc.keys()):
        print(f"\nğŸ“Œ Exit {exit_num}ï¼š")
        for cls in class_names:
            acc = per_class_acc[exit_num].get(cls, 0.0)
            print(f"  {cls:<12}: {acc:.2%}")

    # ===== 3. æ¯ä¸ªå‡ºå£çš„é¢„æµ‹ç±»åˆ«åˆ†å¸ƒï¼ˆç”¨äºå¯è§†åŒ–ï¼‰ =====
    exit_class_pred = pd.crosstab(df['exit'], df['pred'], rownames=['Exit'], colnames=['Predicted Class'])
    exit_class_pred.columns = [class_names[c] for c in exit_class_pred.columns]

    print("\nğŸ“ˆ æ¯ä¸ªå‡ºå£çš„é¢„æµ‹ç±»åˆ«åˆ†å¸ƒï¼š")
    display(exit_class_pred)

    # ===== 4. å¯è§†åŒ–ï¼šæŸ±çŠ¶å›¾ =====
    exit_class_pred.T.plot(kind='bar', figsize=(10, 5))
    plt.title("Exit-wise Predicted Class Distribution")
    plt.xlabel("Class")
    plt.ylabel("Sample Count")
    plt.tight_layout()
    plt.show()

    # ===== 5. å¯è§†åŒ–ï¼šçƒ­åŠ›å›¾ =====
    plt.figure(figsize=(8, 4))
    sns.heatmap(exit_class_pred, annot=True, fmt='d', cmap='YlGnBu')
    plt.title("Exit-Class Prediction Heatmap")
    plt.ylabel("Exit")
    plt.xlabel("Class")
    plt.tight_layout()
    plt.show()


def get_system_status(label, process):
    mem = process.memory_info().rss / 1024 ** 2
    threads = process.num_threads()
    return {
        f"Memory {label} (MB)": round(mem, 2),
        f"Threads {label}": threads
    }



def run_patternA_execution(
    model,
    controller1, controller2,
    inference_loader,
    dataloaders_subset1a, dataloaders_subset1b,
    dataloaders_subset2a, dataloaders_subset2b,
    device='cuda',
    visualize=True
):
    results = {}
    process = psutil.Process()

    # === åŠ è½½æ¨¡å‹åï¼Œè®°å½•åˆå§‹çŠ¶æ€ ===
    model.load_state_dict(torch.load('model_with_exits_new.pth'))
    results.update(get_system_status("After Model Load", process))
    
    # === å†»ç»“ä¸»å¹²ï¼Œè§£å†» early exits ===
    for param in model.parameters():
        param.requires_grad = False
    for param in model.early_exit1.parameters():
        param.requires_grad = True
    for param in model.early_exit2.parameters():
        param.requires_grad = True

    optimizer1 = torch.optim.Adam(model.early_exit1.parameters(), lr=0.01)
    optimizer2 = torch.optim.Adam(model.early_exit2.parameters(), lr=0.01)

    train_args1 = {
        'train_function': trainEE_KL,
        'model': model,
        'id_dataloader': dataloaders_subset1a["train"],
        #'id_testloader': dataloaders_subset1a["test"],
        'ood_dataloader': dataloaders_subset1b["train"],
        'exit_number': 1,
        'criterion_id': nn.CrossEntropyLoss(),
        'optimizer': optimizer1,
        'stepsize': 30,
        'num_epochs': 5,
        'alpha': 1
    }

    train_args2 = {
        'train_function': trainEE_KL,
        'model': model,
        'id_dataloader': dataloaders_subset2a["train"],
        #'id_testloader': dataloaders_subset2a["test"],
        'ood_dataloader': dataloaders_subset2b["train"],
        'exit_number': 2,
        'criterion_id': nn.CrossEntropyLoss(),
        'optimizer': optimizer2,
        'stepsize': 30,
        'num_epochs': 5,
        'alpha': 1
    }

    # === å¯åŠ¨è®­ç»ƒçº¿ç¨‹å‰è®°å½•çŠ¶æ€ ===
    results.update(get_system_status("Before Training", process))

    print("[PatternA] å¯åŠ¨è®­ç»ƒçº¿ç¨‹ Exit1 å’Œ Exit2...")
    train1_timer = Timer("è®­ç»ƒ Exit1 è€—æ—¶")
    train2_timer = Timer("è®­ç»ƒ Exit2 è€—æ—¶")
    train1_timer.start()
    train2_timer.start()
    controller1.start_training(train_function=train_args1.pop('train_function'), **train_args1)
    controller2.start_training(train_function=train_args2.pop('train_function'), **train_args2)

    # === æ¨ç†å‰è®°å½•çŠ¶æ€ ===
    results.update(get_system_status("Before Inference", process))

    # === æ¨ç†è®°å½•ç»“æ„ ===
    exit_logs = defaultdict(list)
    latency_logs = []
    all_logs = {'true': [], 'pred': [], 'exit': []}

    status_recorded_mid_infer = False

    print("[PatternA] å¼€å§‹å®æ—¶æ¨ç†è®°å½•ï¼ˆauto_select=Trueï¼‰...")
    start_infer_time = time.time()

    for batch in inference_loader:
        images, labels = batch[0].to(device), batch[1].to(device)
        try:
            start = time.time()
            with torch.no_grad():
                outputs, exit_idx = model(images, auto_select=True, disabled_exits=[1, 2])
            end = time.time()
            latency_logs.append(end - start)

            probs = F.softmax(outputs, dim=1)
            confs, preds = torch.max(probs, dim=1)

            for i in range(len(exit_idx)):
                exit_number = exit_idx[i].item()
                true_label = labels[i].item()
                pred_label = preds[i].item()

                exit_logs[exit_number].append(true_label)
                all_logs['true'].append(true_label)
                all_logs['pred'].append(pred_label)
                all_logs['exit'].append(exit_number)

            # === ä»…è®°å½•ä¸€æ¬¡è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç³»ç»ŸçŠ¶æ€ ===
            if not status_recorded_mid_infer:
                results.update(get_system_status("during_infer", process))
                status_recorded_mid_infer = True
                time.sleep(0.5)

        except Exception as e:
            print(f"[ERROR] æ¨ç†å¤±è´¥: {e}")

    infer_duration = time.time() - start_infer_time
    print("\n[æ¨ç†å®Œæˆ]")

    # === ç­‰å¾…è®­ç»ƒçº¿ç¨‹ç»“æŸ ===
    controller1.train_thread.join()
    controller2.train_thread.join()
    train1_timer.stop()
    train2_timer.stop()

    # === æœ€åçŠ¶æ€è®°å½• ===
    results.update(get_system_status("After All", process))

    results["Mode"] = "PatternA Execution"
    results["Inference Duration (s)"] = round(infer_duration, 2)
    results["Exit1 Training Time (s)"] = train1_timer.elapsed()
    results["Exit2 Training Time (s)"] = train2_timer.elapsed()
    results["Avg Inference Latency (s)"] = round(np.mean(latency_logs), 4)
    results["Latency Std Dev (s)"] = round(np.std(latency_logs), 4)

    # === å¯è§†åŒ–ä¸å‡†ç¡®ç‡åˆ†æ ===
    if visualize:
        print("\n[å¯è§†åŒ–] å„å‡ºå£ç±»åˆ«åˆ†å¸ƒ")
        _visualize_exit_distribution(exit_logs, title_suffix="(PatternA)")
        analyze_exit_logs_with_accuracy(all_logs, [
            'airplane', 'automobile', 'bird', 'cat', 'deer',
            'dog', 'frog', 'horse', 'ship', 'truck'
        ])

    return results,latency_logs, exit_logs


def run_patternB_execution(
    model,
    dataloaders_subset1a,
    dataloaders_subset1b,
    dataloaders_subset2a,
    dataloaders_subset2b,
    controller1,
    controller2,
    inference_loader,
    trainEE_KL,
    visualize=True,
    device='cuda',
):
    process = psutil.Process()
    # Use unified top-level get_system_status

    results = {}
    exit_logs = defaultdict(list)
    all_logs = {'true': [], 'pred': [], 'exit': []}
    latency_logs = []
    inference_logs_phase1 = defaultdict(list)
    inference_logs_phase2 = defaultdict(list)
    for eid in [0, 1, 2]:
        inference_logs_phase1[eid]
        inference_logs_phase2[eid]

    results.update(get_system_status("After Model Load", process))

    current_exit_mode = {'mode': 'exit1_train'}
    stop_flag = {'stop': False}
    switch_requested = {'flag': False}

    def inference_thread():
        print("[PatternB] å¯åŠ¨æ¨ç†çº¿ç¨‹...")
        start_infer_time = time.time()
        recorded_midpoint = False
        for batch in inference_loader:
            if switch_requested['flag']:
                print("[PatternB] æ£€æµ‹åˆ°æ¨¡å¼åˆ‡æ¢è¯·æ±‚ï¼Œå®Œæˆå½“å‰ batch ååˆ‡æ¢...")
                current_exit_mode['mode'] = 'exit2_train'
                switch_requested['flag'] = False
            images, labels = batch[0].to(device), batch[1].to(device)
            try:
                if current_exit_mode['mode'] == 'exit2_train':
                    disabled_exits = [1]
                elif current_exit_mode['mode'] == 'exit1_train':
                    disabled_exits = [2]
                else:
                    disabled_exits = []
                start = time.time()
                with torch.no_grad():
                    outputs, exit_idx = model(images, auto_select=True, disabled_exits=disabled_exits)
                end = time.time()
                latency_logs.append(end - start)
                if not recorded_midpoint:
                    results.update(get_system_status("during_infer", process))
                    recorded_midpoint = True
                probs = torch.nn.functional.softmax(outputs, dim=1)
                confs, preds = torch.max(probs, dim=1)
                for i in range(len(exit_idx)):
                    exit_number = exit_idx[i].item()
                    true_label = labels[i].item()
                    pred_label = preds[i].item()
                    exit_logs[exit_number].append(true_label)
                    all_logs['true'].append(true_label)
                    all_logs['pred'].append(pred_label)
                    all_logs['exit'].append(exit_number)
                    if current_exit_mode['mode'] == 'exit1_train':
                        inference_logs_phase1[exit_number].append(true_label)
                    else:
                        inference_logs_phase2[exit_number].append(true_label)
                time.sleep(0.5)
            except Exception as e:
                print(f"[ERROR] æ¨ç†å¤±è´¥: {e}")
            if stop_flag['stop']:
                break
        results["Inference Duration (s)"] = round(time.time() - start_infer_time, 2)
        print("[PatternB] æ¨ç†çº¿ç¨‹ç»“æŸ")

    results.update(get_system_status("Before Training", process))
    infer_thread = threading.Thread(target=inference_thread)
    infer_thread.start()

    for param in model.parameters():
        param.requires_grad = False
    for param in model.early_exit1.parameters():
        param.requires_grad = True
    optimizer1 = torch.optim.Adam(model.early_exit1.parameters(), lr=0.01)
    train_args1 = {
        'train_function': trainEE_KL,
        'model': model,
        'id_dataloader': dataloaders_subset1a["train"],
        #'id_testloader': dataloaders_subset1a["test"],
        'ood_dataloader': dataloaders_subset1b["train"],
        'exit_number': 1,
        'criterion_id': nn.CrossEntropyLoss(),
        'optimizer': optimizer1,
        'stepsize': 30,
        'num_epochs': 5,
        'alpha': 1
    }
    print("[PatternB] ç¬¬ä¸€é˜¶æ®µï¼šè®­ç»ƒ Exit1 (Exit2 å’Œä¸»å¹²å¤„ç†æ¨ç†)...")
    train1_timer = Timer("è®­ç»ƒ Exit1 è€—æ—¶")
    train1_timer.start()
    controller1.start_training(train_function=train_args1.pop('train_function'), **train_args1)
    controller1.train_thread.join()
    train1_timer.stop()

    switch_requested['flag'] = True
    for param in model.early_exit1.parameters():
        param.requires_grad = False
    for param in model.early_exit2.parameters():
        param.requires_grad = True
    optimizer2 = torch.optim.Adam(model.early_exit2.parameters(), lr=0.01)
    train_args2 = {
        'train_function': trainEE_KL,
        'model': model,
        'id_dataloader': dataloaders_subset2a["train"],
        #'id_testloader': dataloaders_subset2a["test"],
        'ood_dataloader': dataloaders_subset2b["train"],
        'exit_number': 2,
        'criterion_id': nn.CrossEntropyLoss(),
        'optimizer': optimizer2,
        'stepsize': 30,
        'num_epochs': 5,
        'alpha': 1
    }
    print("[PatternB] ç¬¬äºŒé˜¶æ®µï¼šè®­ç»ƒ Exit2 (Exit1 å’Œä¸»å¹²å¤„ç†æ¨ç†)...")
    train2_timer = Timer("è®­ç»ƒ Exit2 è€—æ—¶")
    train2_timer.start()
    controller2.start_training(train_function=train_args2.pop('train_function'), **train_args2)
    controller2.train_thread.join()
    train2_timer.stop()

    stop_flag['stop'] = True
    infer_thread.join()

    results.update(get_system_status("After All", process))
    results["Mode"] = "PatternB"
    results["Exit1 Training Time (s)"] = train1_timer.elapsed()
    results["Exit2 Training Time (s)"] = train2_timer.elapsed()
    results["Avg Inference Latency (s)"] = round(np.mean(latency_logs), 4)
    results["Latency Std Dev (s)"] = round(np.std(latency_logs), 4)

    if visualize:
        print("\n[å¯è§†åŒ–] ç¬¬ä¸€é˜¶æ®µå„å‡ºå£ç±»åˆ«åˆ†å¸ƒ")
        _visualize_exit_distribution(inference_logs_phase1, title_suffix="(Phase 1)")
        print("\n[å¯è§†åŒ–] ç¬¬äºŒé˜¶æ®µå„å‡ºå£ç±»åˆ«åˆ†å¸ƒ")
        _visualize_exit_distribution(inference_logs_phase2, title_suffix="(Phase 2)")

        print("\n[å¯è§†åŒ–] åˆå¹¶çš„å‡ºå£ç±»åˆ«åˆ†å¸ƒ")
        _visualize_exit_distribution(exit_logs, title_suffix="(Combined)")
        analyze_exit_logs_with_accuracy(all_logs, [
            'airplane', 'automobile', 'bird', 'cat', 'deer',
            'dog', 'frog', 'horse', 'ship', 'truck'
        ])
    return results, latency_logs, exit_logs


def run_shared_parallel_execution(
    model,
    controller1, controller2,
    inference_loader,
    dataloaders_subset1a, dataloaders_subset1b,
    dataloaders_subset2a, dataloaders_subset2b,
    trainEE_KL,
    class_names,
    device='cuda',
    visualize=True  # æ–°å¢å‚æ•°
):


    recorded_during_infer = False
    results = {}
    process = psutil.Process()


    results.update(get_system_status("After Model Load", process))

    for param in model.parameters():
        param.requires_grad = False
    for param in model.early_exit1.parameters():
        param.requires_grad = True
    for param in model.early_exit2.parameters():
        param.requires_grad = True

    results.update(get_system_status("Before Training", process))

    optimizer1 = torch.optim.Adam(model.early_exit1.parameters(), lr=0.01)
    optimizer2 = torch.optim.Adam(model.early_exit2.parameters(), lr=0.01)

    train_args1 = {
        'train_function': trainEE_KL,
        'model': model,
        'id_dataloader': dataloaders_subset1a["train"],
        #'id_testloader': dataloaders_subset1a["test"],
        'ood_dataloader': dataloaders_subset1b["train"],
        'exit_number': 1,
        'criterion_id': nn.CrossEntropyLoss(),
        'optimizer': optimizer1,
        'stepsize': 30,
        'num_epochs': 5,
        'alpha': 1
    }

    train_args2 = {
        'train_function': trainEE_KL,
        'model': model,
        'id_dataloader': dataloaders_subset2a["train"],
        #'id_testloader': dataloaders_subset2a["test"],
        'ood_dataloader': dataloaders_subset2b["train"],
        'exit_number': 2,
        'criterion_id': nn.CrossEntropyLoss(),
        'optimizer': optimizer2,
        'stepsize': 30,
        'num_epochs': 5,
        'alpha': 1
    }

    print("[C-Shared] å¯åŠ¨è®­ç»ƒçº¿ç¨‹ Exit1 å’Œ Exit2...")
    train1_timer = Timer("è®­ç»ƒ Exit1 è€—æ—¶")
    train2_timer = Timer("è®­ç»ƒ Exit2 è€—æ—¶")
    train1_timer.start()
    train2_timer.start()
    controller1.start_training(train_function=train_args1.pop('train_function'), **train_args1)
    controller2.start_training(train_function=train_args2.pop('train_function'), **train_args2)

    # === æ¨ç†è®°å½•ç»“æ„ ===
    exit_logs = defaultdict(list)
    latency_logs = []
    all_logs = {'true': [], 'pred': [], 'exit': []}

    results.update(get_system_status("Before Inference", process))

    print("[C-Shared] å¼€å§‹å…±äº«æ¨¡å‹å®æ—¶æ¨ç†è®°å½•ï¼ˆauto_select=Trueï¼‰...")

    start_infer_time = time.time()

    for batch in inference_loader:
        images, labels = batch[0].to(device), batch[1].to(device)
        try:
            start = time.time()
            with torch.no_grad():
                outputs, exit_idx = model(images, auto_select=True)
            end = time.time()
            latency_logs.append(end - start)

            probs = F.softmax(outputs, dim=1)
            confs, preds = torch.max(probs, dim=1)

            for i in range(len(exit_idx)):
                exit_number = exit_idx[i].item()
                true_label = labels[i].item()
                pred_label = preds[i].item()

                exit_logs[exit_number].append(true_label)
                all_logs['true'].append(true_label)
                all_logs['pred'].append(pred_label)
                all_logs['exit'].append(exit_number)
            if not recorded_during_infer:
                results.update(get_system_status("during_infer", process))
                recorded_during_infer = True

            time.sleep(0.5)

        except Exception as e:
            print(f"[ERROR] æ¨ç†å¤±è´¥: {e}")

    infer_duration = time.time() - start_infer_time
    print("\n[æ¨ç†å®Œæˆ]")

    controller1.train_thread.join()
    train1_timer.stop()
    controller2.train_thread.join()
    train2_timer.stop()

    results.update(get_system_status("After All", process))

    # === ç³»ç»Ÿèµ„æºä¸æ€§èƒ½è®°å½• ===
    results["Mode"] = "Shared Parallel Execution"
    results["Inference Duration (s)"] = round(infer_duration, 2)
    results["Exit1 Training Time (s)"] = train1_timer.elapsed()
    results["Exit2 Training Time (s)"] = train2_timer.elapsed()
    results["Avg Inference Latency (s)"] = round(np.mean(latency_logs), 4)
    results["Latency Std Dev (s)"] = round(np.std(latency_logs), 4)

    # === å¯è§†åŒ–ä¸å‡†ç¡®ç‡åˆ†æ ===
    if visualize:
        print("\n[å¯è§†åŒ–] å„å‡ºå£ç±»åˆ«åˆ†å¸ƒ")
        _visualize_exit_distribution(exit_logs, title_suffix="(Shared Mode)")
        analyze_exit_logs_with_accuracy(all_logs, class_names)

    return results, latency_logs, exit_logs

def run_full_suspension_parallel_realtime_logging(
    model,
    controller1, controller2,
    inference_loader,
    dataloaders_subset1a, dataloaders_subset1b,
    dataloaders_subset2a, dataloaders_subset2b,
    device='cuda',
    visualize=True  # æ–°å¢å‚æ•°
):
    from torch.profiler import profile, ProfilerActivity, tensorboard_trace_handler

    results = {}
    process = psutil.Process()

    # === åŠ è½½æ¨¡å‹åï¼Œè®°å½•åˆå§‹çŠ¶æ€ ===
    model.load_state_dict(torch.load('model_with_exits.pth'))
    results.update(get_system_status("After Model Load", process))
    
    # === å†»ç»“ä¸»å¹²ï¼Œè§£å†» early exits ===
    for param in model.parameters():
        param.requires_grad = False
    for param in model.early_exit1.parameters():
        param.requires_grad = True
    for param in model.early_exit2.parameters():
        param.requires_grad = True

    optimizer1 = torch.optim.Adam(model.early_exit1.parameters(), lr=0.01)
    optimizer2 = torch.optim.Adam(model.early_exit2.parameters(), lr=0.01)

    train_args1 = {
        'train_function': trainEE_KL,
        'model': model,
        'id_dataloader': dataloaders_subset1a["train"],
        'id_testloader': dataloaders_subset1a["test"],
        'ood_dataloader': dataloaders_subset1b["train"],
        'exit_number': 1,
        'criterion_id': nn.CrossEntropyLoss(),
        'optimizer': optimizer1,
        'stepsize': 30,
        'num_epochs': 5,
        'alpha': 1
    }

    train_args2 = {
        'train_function': trainEE_KL,
        'model': model,
        'id_dataloader': dataloaders_subset2a["train"],
        'id_testloader': dataloaders_subset2a["test"],
        'ood_dataloader': dataloaders_subset2b["train"],
        'exit_number': 2,
        'criterion_id': nn.CrossEntropyLoss(),
        'optimizer': optimizer2,
        'stepsize': 30,
        'num_epochs': 5,
        'alpha': 1
    }

    # === å¯åŠ¨è®­ç»ƒçº¿ç¨‹å‰è®°å½•çŠ¶æ€ ===
    results.update(get_system_status("Before Training", process))

    print("[A-Parallel] å¯åŠ¨è®­ç»ƒçº¿ç¨‹ Exit1 å’Œ Exit2...")
    train1_timer = Timer("è®­ç»ƒ Exit1 è€—æ—¶")
    train2_timer = Timer("è®­ç»ƒ Exit2 è€—æ—¶")
    train1_timer.start()
    train2_timer.start()
    controller1.start_training(train_function=train_args1.pop('train_function'), **train_args1)
    controller2.start_training(train_function=train_args2.pop('train_function'), **train_args2)

    # === æ¨ç†å‰è®°å½•çŠ¶æ€ ===
    results.update(get_system_status("Before Inference", process))

    # === æ¨ç†è®°å½•ç»“æ„ ===
    exit_logs = defaultdict(list)
    latency_logs = []
    all_logs = {'true': [], 'pred': [], 'exit': []}

    status_recorded_mid_infer = False

    # === å¯åŠ¨ profiler ä¸€æ¬¡æ€§åŒ…è£¹æ¨ç†é˜¶æ®µ ===
    with profile(
        activities=[ProfilerActivity.CPU,ProfilerActivity.CUDA],
        record_shapes=True,
        profile_memory=True,
        on_trace_ready=tensorboard_trace_handler("./log/trace_full_suspension_infer"),
        schedule=torch.profiler.schedule(wait=0, warmup=0, active=3, repeat=1)
    ) as prof:

        print("[A-Parallel] å¼€å§‹å®æ—¶æ¨ç†è®°å½•ï¼ˆauto_select=Trueï¼‰...")
        start_infer_time = time.time()

        for batch in inference_loader:
            images, labels = batch[0].to(device), batch[1].to(device)
            try:
                start = time.time()
                with torch.no_grad():
                    outputs, exit_idx = model(images, auto_select=True, disabled_exits=[1, 2])
                end = time.time()
                latency_logs.append(end - start)

                probs = F.softmax(outputs, dim=1)
                confs, preds = torch.max(probs, dim=1)

                for i in range(len(exit_idx)):
                    exit_number = exit_idx[i].item()
                    true_label = labels[i].item()
                    pred_label = preds[i].item()

                    exit_logs[exit_number].append(true_label)
                    all_logs['true'].append(true_label)
                    all_logs['pred'].append(pred_label)
                    all_logs['exit'].append(exit_number)

                # profiler æ­¥è¿›
                prof.step() 

                # === ä»…è®°å½•ä¸€æ¬¡è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç³»ç»ŸçŠ¶æ€ ===
                if not status_recorded_mid_infer:
                    results.update(get_system_status("during_infer", process))
                    status_recorded_mid_infer = True
                    time.sleep(0.5)

            except Exception as e:
                print(f"[ERROR] æ¨ç†å¤±è´¥: {e}")

    infer_duration = time.time() - start_infer_time
    print("\n[æ¨ç†å®Œæˆ]")

    # === ç­‰å¾…è®­ç»ƒçº¿ç¨‹ç»“æŸ ===
    controller1.train_thread.join()
    controller2.train_thread.join()
    train1_timer.stop()
    train2_timer.stop()

    # === æœ€åçŠ¶æ€è®°å½• ===
    results.update(get_system_status("After All", process))

    results["Mode"] = "Full Suspension (Realtime Logging)"
    results["Inference Duration (s)"] = round(infer_duration, 2)
    results["Exit1 Training Time (s)"] = train1_timer.elapsed()
    results["Exit2 Training Time (s)"] = train2_timer.elapsed()
    results["Avg Inference Latency (s)"] = round(np.mean(latency_logs), 4)
    results["Latency Std Dev (s)"] = round(np.std(latency_logs), 4)

    # === å¯è§†åŒ–ä¸å‡†ç¡®ç‡åˆ†æ ===
    if visualize:
        print("\n[å¯è§†åŒ–] å„å‡ºå£ç±»åˆ«åˆ†å¸ƒ")
        _visualize_exit_distribution(exit_logs, title_suffix="(Phase 1)")
        analyze_exit_logs_with_accuracy(all_logs, [
            'airplane', 'automobile', 'bird', 'cat', 'deer',
            'dog', 'frog', 'horse', 'ship', 'truck'
        ])

    return results, latency_logs, exit_logs


def run_pattern_O_no_training(
    model,
    inference_loader,
    class_names,
    device='cuda',
    visualize=True
):
    import time, psutil
    from collections import defaultdict
    import numpy as np
    import torch.nn.functional as F

    results = {}
    process = psutil.Process()

    # Use unified top-level get_system_status

    # === åŠ è½½æ¨¡å‹ ===
    model.eval()
    results.update(get_system_status("After model load", process))
    # === æ¨ç†è®°å½•ç»“æ„ ===
    exit_logs = defaultdict(list)
    latency_logs = []
    all_logs = {'true': [], 'pred': [], 'exit': []}

    print("[Pattern-O] å¼€å§‹æ¨ç†è®°å½•ï¼ˆæ— è®­ç»ƒçº¿ç¨‹ï¼Œauto_select=Trueï¼‰...")

    start_infer_time = time.time()
    recorded_during_infer = False  # æ ‡è®°æ˜¯å¦å·²è®°å½•ä¸­é€”èµ„æºçŠ¶æ€

    for batch in inference_loader:
        images, labels = batch[0].to(device), batch[1].to(device)
        try:
            start = time.time()
            with torch.no_grad():
                outputs, exit_idx = model(images, auto_select=True)
            end = time.time()
            latency_logs.append(end - start)

            probs = F.softmax(outputs, dim=1)
            confs, preds = torch.max(probs, dim=1)

            for i in range(len(exit_idx)):
                exit_number = exit_idx[i].item()
                true_label = labels[i].item()
                pred_label = preds[i].item()

                exit_logs[exit_number].append(true_label)
                all_logs['true'].append(true_label)
                all_logs['pred'].append(pred_label)
                all_logs['exit'].append(exit_number)
            if not recorded_during_infer:
                results.update(get_system_status("during_infer", process))
                recorded_during_infer = True
            time.sleep(0.5)
        except Exception as e:
            print(f"[ERROR] æ¨ç†å¤±è´¥: {e}")

    infer_duration = time.time() - start_infer_time
    print("\n[æ¨ç†å®Œæˆ]")

    # === ç³»ç»Ÿèµ„æºä¸æ€§èƒ½è®°å½• ===
    results.update(get_system_status("After all", process))

    results["Mode"] = "Pattern-O (No Training)"
    results["Inference Duration (s)"] = round(infer_duration, 2)
    results["Avg Inference Latency (s)"] = round(np.mean(latency_logs), 4)
    results["Latency Std Dev (s)"] = round(np.std(latency_logs), 4)

    if visualize:
        print("\n[å¯è§†åŒ–] å„å‡ºå£ç±»åˆ«åˆ†å¸ƒï¼š")
        _visualize_exit_distribution(exit_logs, title_suffix="(No Training Mode)")
        analyze_exit_logs_with_accuracy(all_logs, class_names)

    return results, latency_logs, exit_logs



def run_single_exit_training(
    model,
    dataloaders_subset_a,
    dataloaders_subset_b,
    exit_number=1
    
):
    """
    åªè®­ç»ƒä¸€ä¸ª early exitï¼ˆexit_number=1 æˆ– 2ï¼‰ï¼Œæ— æ¨ç†éƒ¨åˆ†ã€‚
    """
    results = {}
    process = psutil.Process()

    # === åŠ è½½æ¨¡å‹åï¼Œè®°å½•åˆå§‹çŠ¶æ€ ===
    results.update(get_system_status("After Model Load", process))

    # === å†»ç»“ä¸»å¹²ï¼Œè§£å†»æŒ‡å®š early exit ===
    for param in model.parameters():
        param.requires_grad = False
    if exit_number == 1:
        for param in model.early_exit1.parameters():
            param.requires_grad = True
        optimizer = torch.optim.Adam(model.early_exit1.parameters(), lr=0.01)
    elif exit_number == 2:
        for param in model.early_exit2.parameters():
            param.requires_grad = True
        optimizer = torch.optim.Adam(model.early_exit2.parameters(), lr=0.01)
    else:
        raise ValueError("exit_number must be 1 or 2")

    train_args = {
        'train_function': trainEE_KL,
        'model': model,
        'id_dataloader': dataloaders_subset_a["train"],
        'id_testloader': dataloaders_subset_a["test"],
        'ood_dataloader': dataloaders_subset_b["train"],
        'exit_number': exit_number,
        'criterion_id': nn.CrossEntropyLoss(),
        'optimizer': optimizer,
        'stepsize': 30,
        'num_epochs': 5,
        'alpha': 1
    }

    results.update(get_system_status("Before Training", process))

    print(f"[SingleExit] å¯åŠ¨è®­ç»ƒçº¿ç¨‹ Exit{exit_number} ...")
    train_timer = Timer(f"è®­ç»ƒ Exit{exit_number} è€—æ—¶")
    train_timer.start()
    controller = TrainingController()
    controller.start_training(train_function=train_args.pop('train_function'), **train_args)
    controller.train_thread.join()
    train_timer.stop()

    results.update(get_system_status("After Training", process))
    results["Mode"] = f"Single Exit{exit_number} Training"
    results[f"Exit{exit_number} Training Time (s)"] = train_timer.elapsed()

    print(f"[SingleExit] Exit{exit_number} è®­ç»ƒå®Œæˆ")



def run_training_with_profiler(model, dataloaders_subset_a, ood_dataloaders, exit_number=1):
    import os
    from torch.profiler import profile, ProfilerActivity, tensorboard_trace_handler


    log_name = f'prof_test_EE{exit_number}'
    os.makedirs(f'./log/{log_name}', exist_ok=True)    
    # ... setup optimizer, criterion etc. ...
        # === å†»ç»“ä¸»å¹²ï¼Œè§£å†»æŒ‡å®š early exit ===
    for param in model.parameters():
        param.requires_grad = False
    if exit_number == 1:
        for param in model.early_exit1.parameters():
            param.requires_grad = True
        optimizer = torch.optim.Adam(model.early_exit1.parameters(), lr=0.01)
    elif exit_number == 2:
        for param in model.early_exit2.parameters():
            param.requires_grad = True
        optimizer = torch.optim.Adam(model.early_exit2.parameters(), lr=0.01)
    else:
        raise ValueError("exit_number must be 1 or 2")
    
    criterion_id = nn.CrossEntropyLoss()
    model.to('cuda')

    # Use the profiler to wrap the call to our new function
    with profile(
        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],
        schedule=torch.profiler.schedule(wait=1, warmup=1, active=5, repeat=1),
        on_trace_ready=tensorboard_trace_handler(f'./log/{log_name}'),
        record_shapes=True,
        profile_memory=True,
        with_stack=True
    ) as prof:
        
        print(f"[Profiler] Starting profiling for Exit{exit_number}...")
        
        trainEE_KL_for_profiling(
            model=model,
            id_dataloader=dataloaders_subset_a["train"],
            ood_dataloader=ood_dataloaders["train"],
            exit_number=exit_number,
            criterion_id=criterion_id,
            optimizer=optimizer,
            num_epochs=5,
            prof=prof,  # Pass the profiler object!
            profile_steps=10 # Ensure this is >= wait + warmup + active
        )



def run_testing_with_profiler(
    model,
    test_loader,
    exit_number=None,  # None for auto_select, 1/2/3 for forced exit    
    profile_steps=10
):
    """
    Profile the inference process for the given model and test_loader.
    Allows forcing a specific exit or using auto_select.
    """
    import os
    from torch.profiler import profile, ProfilerActivity, tensorboard_trace_handler
    import torch
    log_name = f'prof_test_EE{exit_number}'
    os.makedirs(f'./log/{log_name}', exist_ok=True)
    model.eval()
    model.to('cuda')

    with profile(
        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],
        schedule=torch.profiler.schedule(wait=1, warmup=1, active=profile_steps, repeat=1),
        on_trace_ready=tensorboard_trace_handler(f'./log/{log_name}'),
        record_shapes=True,
        profile_memory=True,
        with_stack=True
    ) as prof:
        print(f"[Profiler] Starting inference profiling (exit={exit_number})...")
        step_count = 0
        with torch.no_grad():
            for batch in test_loader:
                images, labels = batch[0].to('cuda'), batch[1].to('cuda')
                if exit_number == 1:
                    outputs, _ = model(images, return_exit1=True)
                elif exit_number == 2:
                    outputs, _ = model(images, return_exit2=True)
                elif exit_number == 3:
                    outputs, _ = model(images)
                else:
                    outputs, _ = model(images, auto_select=True)
                # (Optional) You can print or log outputs here
                prof.step()
                step_count += 1
                if step_count >= profile_steps:
                    print(f"[Profiler] Reached {profile_steps} steps. Stopping inference.")
                    break